Adapted from [DSSG](https://github.com/dssg/mlforpublicpolicylab/blob/8ff06d1b7803ea2a23bcff99d698758528f7ff68/project/final_project_presentation.md)


# Final Project Presentation

**NOTE: Presentations will take place during class the 3 scheduled course meetings of the semester. Please upload your slides on canvas before the presentation.**

Each individual or team will have 15 minutes for their presentation (plus 5 minutes for questions).

## Timing
Practice your timing before and have a plan for the last 30 seconds. If you're out of time, what do you want to say in the last 30 seconds?

## Content
The presentation should be clear, well-organized, and **at an appropriate level of depth for the decision-makers relevant to your project (as opposed to ML experts)**

## Suggested Structure

1. What problem are you solving and why is it important?  Be specific about goals, potential policy impact, and efficiency/equity/effectiveness trade-offs
1. What data did you use?
1. Machine Learning Formulation, Analysis, and Evaluation - described in a way that makes sense to decision-makers
    - formulation of the problem
    - what are your rows, what are your labels, what are your features
    - how did you validate - training/validation splits, evaluation metrics, sensible baseline
    - results â€“ performance, important features, and bias audit
1. Caveats: based on the limitations of your data or analysis
1. Future Work

# Evaluation Criteria

- Goals/Context:
    - The project has a clearly-defined problem statement.
    - The project is well motivated and achieves its described goals / addresses its posed research question(s).
    - Thoughtful consideration of balancing equity, efficiency, and effectiveness, as well as other potential ethical issues and mitigation strategies.
- Data:
    - The data description and data exploration shows that the data used is relevant and sufficient for the problem.
- Analysis: The analysis is done correctly and is evaluated appropriately
    - The machine learning models used are appropriate for the task and well-justified.
    - The evaluation methodology is appropriate for the task and matches the operational use of this analysis/models.
    - Training and validation set (and process) is well described.
    - The correct metrics are being optimized for and optimizing for those metrics achieve the policy goals described.
- Results:
    - Evaluation results are described for every train/validate set, metric, and model used
    - Performance is compared against a sensible baseline that reflects what a decision-maker might do in the absence of a machine learning model.
    - The selection of the final model recommended for use is well described.
    - The model interpretation is done well.
    - To whatever degree applicable, models are audited for bias and fairness (motivated by the correct bias and fairness metrics and groups of interest) and results provided.
- Caveats:
    - Caveats of the project and recommendations are provided to a policy audience based on the limitations of the data and/or the analysis.
    - Future recommendations on how to improve the analysis are provided
